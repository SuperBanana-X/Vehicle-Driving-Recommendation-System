{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f0a7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 label files\n",
      "Handled 100/5000 files\n",
      "Handled 200/5000 files\n",
      "Handled 300/5000 files\n",
      "Handled 400/5000 files\n",
      "Handled 500/5000 files\n",
      "Handled 600/5000 files\n",
      "Handled 700/5000 files\n",
      "Handled 800/5000 files\n",
      "Handled 900/5000 files\n",
      "Handled 1000/5000 files\n",
      "Handled 1100/5000 files\n",
      "Handled 1200/5000 files\n",
      "Handled 1300/5000 files\n",
      "Handled 1400/5000 files\n",
      "Handled 1500/5000 files\n",
      "Handled 1600/5000 files\n",
      "Handled 1700/5000 files\n",
      "Handled 1800/5000 files\n",
      "Handled 1900/5000 files\n",
      "Handled 2000/5000 files\n",
      "Handled 2100/5000 files\n",
      "Handled 2200/5000 files\n",
      "Handled 2300/5000 files\n",
      "Handled 2400/5000 files\n",
      "Handled 2500/5000 files\n",
      "Handled 2600/5000 files\n",
      "Handled 2700/5000 files\n",
      "Handled 2800/5000 files\n",
      "Handled 2900/5000 files\n",
      "Handled 3000/5000 files\n",
      "Handled 3100/5000 files\n",
      "Handled 3200/5000 files\n",
      "Handled 3300/5000 files\n",
      "Handled 3400/5000 files\n",
      "Handled 3500/5000 files\n",
      "Handled 3600/5000 files\n",
      "Handled 3700/5000 files\n",
      "Handled 3800/5000 files\n",
      "Handled 3900/5000 files\n",
      "Handled 4000/5000 files\n",
      "Handled 4100/5000 files\n",
      "Handled 4200/5000 files\n",
      "Handled 4300/5000 files\n",
      "Handled 4400/5000 files\n",
      "Handled 4500/5000 files\n",
      "Handled 4600/5000 files\n",
      "Handled 4700/5000 files\n",
      "Handled 4800/5000 files\n",
      "Handled 4900/5000 files\n",
      "Handled 5000/5000 files\n",
      "Convert Successfully! Handle 5000 files, jump 0 files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "frames_dir = Path(\"frames\")\n",
    "labels_dir = Path(\"labels\")\n",
    "output_dir = Path(\"yolo_labels\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "detection_classes = [1, 2, 5, 6, 11, 12]  # vehicle, person, bicycle, motorcycle, traffic light, traffic sign\n",
    "class_colors = {}\n",
    "for label_info in config['labels']:\n",
    "    class_colors[label_info['id']] = tuple(label_info['color'])\n",
    "\n",
    "# map\n",
    "yolo_mapping = {}\n",
    "yolo_names = []\n",
    "for i, class_id in enumerate(detection_classes):\n",
    "    yolo_mapping[class_id] = i\n",
    "    for label_info in config['labels']:\n",
    "        if label_info['id'] == class_id:\n",
    "            yolo_names.append(label_info['label'])\n",
    "            break\n",
    "\n",
    "with open('classes.txt', 'w') as f:\n",
    "    for name in yolo_names:\n",
    "        f.write(f\"{name}\\n\")\n",
    "\n",
    "label_files = list(sorted(labels_dir.glob(\"*.png\")))\n",
    "total_files = len(label_files)\n",
    "print(f\"Found {total_files} label files\")\n",
    "\n",
    "processed_count = 0\n",
    "error_count = 0\n",
    "\n",
    "# Handle the label files\n",
    "for i, label_file in enumerate(label_files):\n",
    "    base_name = label_file.stem\n",
    "    if \"_gt_id\" in base_name:\n",
    "        base_name = base_name.replace(\"_gt_id\", \"\")\n",
    "    img_file = frames_dir / f\"{base_name}_img.jpg\"\n",
    "    \n",
    "    if not img_file.exists():\n",
    "        error_count += 1\n",
    "        if error_count <= 5 or error_count % 100 == 0:\n",
    "            print(f\"Jump ({i+1}/{total_files}): Not found: {img_file}\")\n",
    "        continue\n",
    "    \n",
    "    # read the mask\n",
    "    mask = cv2.imread(str(label_file))\n",
    "    if mask is None:\n",
    "        print(f\"can not read mask: {label_file}\")\n",
    "        continue\n",
    "    \n",
    "    # read the image\n",
    "    img = cv2.imread(str(img_file))\n",
    "    if img is None:\n",
    "        print(f\"can not read image: {img_file}\")\n",
    "        continue\n",
    "    \n",
    "    img_height, img_width = img.shape[:2]\n",
    "    \n",
    "    yolo_file = output_dir / f\"{base_name}.txt\"\n",
    "    \n",
    "    with open(yolo_file, 'w') as f:\n",
    "        #read the mask\n",
    "        for class_id in detection_classes:\n",
    "            # Create binary mask for this class\n",
    "            binary_mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "            \n",
    "            # The mask pixels have RGB values equal to [class_id, class_id, class_id]\n",
    "            class_value = np.array([class_id, class_id, class_id])\n",
    "            mask_match = np.all(mask == class_value, axis=2)\n",
    "            binary_mask[mask_match] = 255\n",
    "            \n",
    "            if np.sum(binary_mask) == 0:  # Skip if no pixels for this class\n",
    "                continue\n",
    "                \n",
    "            # Continue with contour detection as before\n",
    "            contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            # create a mask for the class\n",
    "            for contour in contours:\n",
    "                area = cv2.contourArea(contour)\n",
    "                if area < 100:  \n",
    "                    continue\n",
    "                    \n",
    "               \n",
    "                x_min, y_min, w, h = cv2.boundingRect(contour)\n",
    "                x_max = x_min + w\n",
    "                y_max = y_min + h\n",
    "                \n",
    "                \n",
    "                yolo_class = yolo_mapping[class_id]\n",
    "                x_center = (x_min + x_max) / 2 / img_width\n",
    "                y_center = (y_min + y_max) / 2 / img_height\n",
    "                width = w / img_width\n",
    "                height = h / img_height\n",
    "                \n",
    "                f.write(f\"{yolo_class} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "    \n",
    "    processed_count += 1\n",
    "    if processed_count % 100 == 0:\n",
    "        print(f\"Handled {processed_count}/{total_files} files\")\n",
    "\n",
    "print(f\"Convert Successfully! Handle {processed_count} files, jump {error_count} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85cf79c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 5000\n",
      "Train set: 4000\n",
      "Test set: 1000\n",
      "Data set divided successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "random.seed(42)\n",
    "frames_dir = Path(\"frames\")\n",
    "yolo_labels_dir = Path(\"yolo_labels\")\n",
    "dataset_dir = Path(\"dataset\")\n",
    "\n",
    "# train & test\n",
    "for split in ['train', 'test']:\n",
    "    (dataset_dir / split / 'images').mkdir(parents=True, exist_ok=True)\n",
    "    (dataset_dir / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "all_labels = list(yolo_labels_dir.glob('*.txt'))\n",
    "base_names = [label.stem for label in all_labels]\n",
    "valid_names = []\n",
    "for name in base_names:\n",
    "    img_file = frames_dir / f\"{name}_img.jpg\"\n",
    "    if img_file.exists():\n",
    "        valid_names.append(name)\n",
    "\n",
    "# 80% train, 20% test\n",
    "random.shuffle(valid_names)\n",
    "split_idx = int(len(valid_names) * 0.8)\n",
    "train_names = valid_names[:split_idx]\n",
    "test_names = valid_names[split_idx:]\n",
    "\n",
    "print(f\"Total data: {len(valid_names)}\")\n",
    "print(f\"Train set: {len(train_names)}\")\n",
    "print(f\"Test set: {len(test_names)}\")\n",
    "\n",
    "# Copy files to train/test directories\n",
    "def copy_files(names, split):\n",
    "    for name in names:\n",
    "        src_img = frames_dir / f\"{name}_img.jpg\"\n",
    "        dst_img = dataset_dir / split / 'images' / f\"{name}.jpg\"\n",
    "        shutil.copy(src_img, dst_img)\n",
    "        src_label = yolo_labels_dir / f\"{name}.txt\"\n",
    "        dst_label = dataset_dir / split / 'labels' / f\"{name}.txt\"\n",
    "        shutil.copy(src_label, dst_label)\n",
    "\n",
    "copy_files(train_names, 'train')\n",
    "copy_files(test_names, 'test')\n",
    "\n",
    "print(\"Data set divided successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae969e51",
   "metadata": {},
   "source": [
    "3. 创建YOLO配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63c34201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO yaml file completed: driveseg.yaml\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "classes = []\n",
    "with open('classes.txt', 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "dataset_config = {\n",
    "    'path': str(Path.cwd() / 'dataset'),  \n",
    "    'train': 'train/images',  \n",
    "    'val': 'test/images', \n",
    "    'nc': len(classes),       \n",
    "    'names': classes          \n",
    "}\n",
    "\n",
    "with open('driveseg.yaml', 'w') as f:\n",
    "    yaml.dump(dataset_config, f, sort_keys=False)\n",
    "\n",
    "print(\"YOLO yaml file completed: driveseg.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e00df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# YOLOv8 training parameters\n",
    "img_size = 640 \n",
    "batch_size = 16  \n",
    "epochs = 100    \n",
    "\n",
    "# model size\n",
    "model_size = 'n'  # n(nano), s(small),m(medium), l(large), x(xlarge)\n",
    "\n",
    "print(f\"Start train YOLOv8{model_size}model...\")\n",
    "print(f\"Image size: {img_size}px\")\n",
    "print(f\"Batching Size: {batch_size}\")\n",
    "print(f\"Epochs: {epochs}\")\n",
    "\n",
    "# Create the runs directory\n",
    "runs_dir = Path(\"runs\")\n",
    "runs_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO(f'yolov8{model_size}.pt')\n",
    "\n",
    "# Define the autosave callback\n",
    "def on_train_epoch_end(trainer):\n",
    "    epoch = trainer.epoch\n",
    "    print(f\"\\nSave the {epoch}th model weight...\")\n",
    "    return trainer\n",
    "\n",
    "model.add_callback(\"on_train_epoch_end\", on_train_epoch_end)\n",
    "\n",
    "\n",
    "results = model.train(\n",
    "    data='driveseg.yaml',\n",
    "    epochs=epochs,\n",
    "    imgsz=img_size,\n",
    "    batch=batch_size,\n",
    "    name='driveseg_yolo_model',  \n",
    "    patience=20,                  \n",
    "    save=True,\n",
    "    save_period=1,                   \n",
    "    #device=0,                    \n",
    "    val=True,\n",
    "    project=\"runs\",\n",
    "    exist_ok=True,\n",
    "    pretrained=True                   \n",
    ")\n",
    "\n",
    "print(\"\\nFinish!\")\n",
    "print(f\"Result in: {model.trainer.save_dir}\")\n",
    "print(\"Best Model: best.pt\")\n",
    "print(\"Last Model: last.pt\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.val(data='driveseg.yaml')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddd4f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
